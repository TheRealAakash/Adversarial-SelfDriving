{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a62bc17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs successfully enabled\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'ClassificationModels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b09b57dc3326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mSHOW_DATASET\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ClassificationModels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlist_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \"\"\"\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'ClassificationModels'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ClassificationModels import targetModel\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import skimage.morphology as morp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from skimage.filters import rank\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, Dropout, Activation, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model\n",
    "from settings import settings\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPUs successfully enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "(X_train, y_train), (X_valid, y_valid), (X_test, y_test), signs = settings.DATA_LOADER()\n",
    "n_train = X_train.shape[0]  # Number of training examples\n",
    "n_test = X_test.shape[0]  # Number of testing examples\n",
    "n_validation = X_valid.shape[0]  # Number of validation examples\n",
    "n_classes = len(np.unique(y_train))  # Number of highres in dataset\n",
    "EPOCHS = settings.target_model_epochs\n",
    "BATCH_SIZE = settings.target_batch_size\n",
    "SHOW_DATASET = True\n",
    "\n",
    "os.chdir(\"ClassificationModels\")\n",
    "def list_images(dataset, dataset_y, ylabel=\"\", cmap=None):\n",
    "    \"\"\"\n",
    "    Display a list of images in a single figure with matplotlib.\n",
    "        Parameters:\n",
    "            dataset: An np.array compatible with plt.imshow.\n",
    "            dataset_y (Default = No label): A string to be used as a label for each image.\n",
    "            cmap (Default = None): Used to display gray images.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 16))\n",
    "    for i in range(6):\n",
    "        plt.subplot(1, 6, i + 1)\n",
    "        indx = random.randint(0, len(dataset) - 1)\n",
    "        # Use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(dataset[indx].shape) == 2 else cmap\n",
    "        plt.imshow(dataset[indx], cmap=cmap)\n",
    "        font = {\n",
    "            'color': 'black',\n",
    "            'weight': 'normal',\n",
    "            'size': 17,\n",
    "        }\n",
    "        plt.xlabel(signs[dataset_y[indx]], fontdict=font)\n",
    "        # plt.ylabel(ylabel)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def histogram_plot(dataset, label):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the input data.\n",
    "        Parameters:\n",
    "            dataset: Input data to be plotted as a histogram.\n",
    "            lanel: A string to be used as a label for the histogram.\n",
    "    \"\"\"\n",
    "    hist, bins = np.histogram(dataset, bins=n_classes)\n",
    "    width = 0.7 * (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    plt.bar(center, hist, align='center', width=width)\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(\"Image count\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualizeDataset():\n",
    "    # Plotting sample examples, before pre-processing\n",
    "    list_images(X_train, y_train, \"Training example\")\n",
    "    # list_images(X_test, y_test, \"Testing example\")\n",
    "    # list_images(X_valid, y_valid, \"Validation example\")\n",
    "    # Show frequency of each label\n",
    "    histogram_plot(y_train, \"Training examples\")\n",
    "    histogram_plot(y_test, \"Testing examples\")\n",
    "    histogram_plot(y_valid, \"Validation examples\")\n",
    "\n",
    "\n",
    "def gray_scale(image):\n",
    "    \"\"\"\n",
    "    Convert images to gray scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "def local_histo_equalize(image):\n",
    "    \"\"\"\n",
    "    Apply local histogram equalization to grayscale images.\n",
    "        Parameters:\n",
    "            image: A grayscale image.\n",
    "    \"\"\"\n",
    "    kernel = morp.disk(30)\n",
    "    img_local = rank.equalize(image, selem=kernel)\n",
    "    return img_local\n",
    "\n",
    "\n",
    "def image_normalize(image):\n",
    "    \"\"\"\n",
    "    Normalize images to [0, 1] scale.\n",
    "        Parameters:\n",
    "            image: An np.array compatible with plt.imshow.\n",
    "    \"\"\"\n",
    "    image = np.divide(image, 255)\n",
    "    return image\n",
    "\n",
    "\n",
    "def preprocess(data):  # step 3\n",
    "    data = (np.array(data) * 2. / 255 - 1).reshape((len(data), settings.IMG_W, settings.IMG_H, settings.CHANNELS))  # pixel values in range [-1., 1.] for D\n",
    "    return data\n",
    "    # Sample images after greyscaling\n",
    "    gray_images = list(map(gray_scale, data))\n",
    "    # list_images(gray_images, y_train, \"Gray Scale image\", \"gray\")\n",
    "    # Equalize images using skimage to improve contrast\n",
    "    # Sample images after Local Histogram Equalization\n",
    "    equalized_images = list(map(local_histo_equalize, gray_images))\n",
    "    # list_images(equalized_images, y_train, \"Equalized Image\", \"gray\")\n",
    "\n",
    "    # Normalize images\n",
    "    n_training = data.shape\n",
    "    normalized_images = np.zeros((n_training[0], n_training[1], n_training[2]))\n",
    "    for i, img in enumerate(equalized_images):\n",
    "        normalized_images[i] = image_normalize(img)\n",
    "    # list_images(normalized_images, y_train, \"Normalized Image\", \"gray\")\n",
    "    normalized_images = normalized_images[..., None]\n",
    "    return normalized_images\n",
    "\n",
    "\n",
    "class KerasModel:\n",
    "    def __init__(self, n_out=n_classes):\n",
    "        self.n_out = n_out\n",
    "        self.model = self.setup_model_keras()\n",
    "        # self.model.summary()\n",
    "\n",
    "    def inceptionModel(self):\n",
    "        model = keras.applications.InceptionV3(\n",
    "            include_top=True,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=1000,\n",
    "            classifier_activation=\"softmax\",\n",
    "        )\n",
    "        model.compile()\n",
    "        return model\n",
    "\n",
    "    def setup_model_keras(self):\n",
    "        model = targetModel.build_model(self.n_out)\n",
    "        return model\n",
    "\n",
    "    def y_predict(self, X_data):\n",
    "        predictions = []\n",
    "        ps = self.model.predict(X_data)\n",
    "        for p in ps:\n",
    "            predictions.append(np.argmax(p))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def y_predict_prob(self, X_data, processed=False):\n",
    "        X_data = preprocess([X_data])\n",
    "        prob = self.model.predict(X_data)\n",
    "        return prob\n",
    "\n",
    "    def y_predict_topk_prob_and_pred(self, data, top_k=5):\n",
    "        probs = self.model.predict(data)\n",
    "        y_probs = []\n",
    "        y_preds = []\n",
    "        for prob in probs:\n",
    "            y_pred = []\n",
    "            y_prob = []\n",
    "            for i in range(top_k):\n",
    "                y_pred.append(np.argmax(prob))\n",
    "                y_prob.append(prob[y_pred[-1]])\n",
    "                prob[y_pred[-1]] = 0\n",
    "            y_probs.append(y_prob)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_probs), np.array(y_preds)\n",
    "\n",
    "    def y_predict_topk(self, data, top_k=5):\n",
    "        probs = self.model.predict(data)\n",
    "        y_preds = []\n",
    "        for prob in probs:\n",
    "            y_pred = []\n",
    "            for i in range(top_k):\n",
    "                y_pred.append(np.argmax(prob))\n",
    "                prob[y_pred[-1]] = 0\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n",
    "\n",
    "    def evaluate(self, X_data, y_data):\n",
    "        score = self.model.evaluate(X_data, y_data)\n",
    "        return score\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "\n",
    "def trainModelKeras(normalized_images):\n",
    "    global X_train, y_train\n",
    "    kerasModel = KerasModel(n_out=n_classes)\n",
    "    # Validation set preprocessing\n",
    "    X_valid_preprocessed = preprocess(X_valid)\n",
    "    y_train_onehot = to_categorical(y_train, n_classes)\n",
    "    y_valid_onehot = to_categorical(y_valid, n_classes)\n",
    "    kerasModel.model.fit(normalized_images, y_train_onehot, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                         validation_data=(X_valid_preprocessed, y_valid_onehot))\n",
    "    kerasModel.model.save(f\"{settings.models_dir}/{settings.model_name}\", save_format='h5')\n",
    "    return kerasModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def showTestImages(test_data, model):\n",
    "    new_test_images_preprocessed = preprocess(np.asarray(test_data))\n",
    "    # get predictions\n",
    "    y_prob, y_pred = model.y_predict_topk_prob_and_pred(new_test_images_preprocessed)\n",
    "    # generate summary of results\n",
    "    figure, axes = plt.figure(figsize=(15, 16))\n",
    "    new_test_images_len = len(new_test_images_preprocessed)\n",
    "    for i in range(new_test_images_len):\n",
    "        plt.subplot(new_test_images_len, 2, 2 * i + 1)\n",
    "        plt.imshow(test_data[i])\n",
    "        plt.title(signs[y_pred[i][0]])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(new_test_images_len, 2, 2 * i + 2)\n",
    "        plt.barh(np.arange(1, 6, 1), y_prob[i, :])\n",
    "        labels = [signs[j] for j in y_pred[i]]\n",
    "        plt.yticks(np.arange(1, 6, 1), labels)\n",
    "    figure.tight_layout(w_pad=3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    global X_train, y_train\n",
    "    useTests = True\n",
    "    loadPrevModel = True\n",
    "    # Step 3, preprocessing\n",
    "    if SHOW_DATASET:\n",
    "        visualizeDataset()\n",
    "    # Randomize dataset to improve training, using sklearn\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train_normalized = preprocess(X_train)\n",
    "    #  Step 4, training\n",
    "    if loadPrevModel:\n",
    "        kerasModel = KerasModel(n_out=n_classes)\n",
    "        kerasModel.load_model(f\"{settings.models_dir}/{settings.model_name}\")\n",
    "    else:\n",
    "        kerasModel = trainModelKeras(X_train_normalized)\n",
    "\n",
    "    # Step 5, testing\n",
    "    if useTests:\n",
    "        X_test_preprocessed = preprocess(X_test)\n",
    "        y_test_onehot = to_categorical(y_test, n_classes)\n",
    "\n",
    "        y_pred = kerasModel.y_predict(X_test_preprocessed)\n",
    "        print(sum(y_test == y_pred))\n",
    "        test_accuracy = sum(y_test == y_pred) / len(y_test)\n",
    "        print(\"Test Accuracy = {:.1f}%\".format(test_accuracy * 100))\n",
    "\n",
    "        # Show model results, and failures\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.log(.0001 + cm)\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Log of normalized Confusion Matrix')\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "    if useTests and False:\n",
    "        # Step 6, testing new images(outside dataset)\n",
    "        new_test_images = []\n",
    "        path = 'datasets/traffic-signs-data/new_test_images/'\n",
    "        for image in os.listdir(path):\n",
    "            img = cv2.imread(path + image)\n",
    "            img = cv2.resize(img, (32, 32))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            new_test_images.append(img)\n",
    "        new_IDs = [13, 3, 14, 27, 17]\n",
    "        print(\"Number of new testing examples: \", len(new_test_images))\n",
    "\n",
    "        plt.figure(figsize=(15, 16))\n",
    "        for i in range(len(new_test_images)):\n",
    "            plt.subplot(2, 5, i + 1)\n",
    "            plt.imshow(new_test_images[i])\n",
    "            plt.xlabel(signs[new_IDs[i]])\n",
    "            plt.ylabel(\"New testing image\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#\n",
    "# # New test data preprocessing\n",
    "# showTestImagesWithLabels(new_test_images, new_IDs, kerasModel)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # wandb.init(project='Adversarial-SelfDriving', entity='therealaakash', config=configs)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede80336",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasModel = KerasModel(n_out=n_classes)\n",
    "kerasModel.load_model(f\"{settings.models_dir}/{settings.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "showTestImagesWithLabels(test_data=X_test[0:5], test_labels=y_test[0:5], model=kerasModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ef24f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showTestImagesWithLabels(test_data, test_labels, model, print_new_acc=False):\n",
    "    new_test_images_preprocessed = preprocess(np.asarray(test_data))\n",
    "    font = {\n",
    "        'color': 'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 18,\n",
    "    }\n",
    "    # get predictions\n",
    "    y_prob, y_pred = model.y_predict_topk_prob_and_pred(new_test_images_preprocessed)\n",
    "    # generate summary of results\n",
    "    test_accuracy = 0\n",
    "    for i in enumerate(new_test_images_preprocessed):\n",
    "        accu = test_labels[i[0]] == np.asarray(y_pred[i[0]])[0]\n",
    "        if accu == True:\n",
    "            test_accuracy += 0.2\n",
    "    if print_new_acc:\n",
    "        print(\"New Images Test Accuracy = {:.1f}%\".format(test_accuracy * 100))\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 16))\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    new_test_images_len = len(new_test_images_preprocessed)\n",
    "    for i in range(new_test_images_len):\n",
    "        plt.subplot(new_test_images_len, 2, i*2 + 1)\n",
    "        plt.imshow(test_data[i])\n",
    "        plt.title(signs[test_labels[i]], fontdict=font)\n",
    "        #  plt.title(signs[y_pred[i][0]])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(new_test_images_len, 2, 2 * i + 2)\n",
    "        plt.barh(np.arange(1, 6, 1), y_prob[i, :] * 100)\n",
    "        labels = [signs[j] for j in y_pred[i]]\n",
    "        plt.tick_params(axis='y', labelsize=18)\n",
    "        plt.yticks(np.arange(1, 6, 1), labels)\n",
    "    plt.subplots_adjust(right=1.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7a78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee227c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
